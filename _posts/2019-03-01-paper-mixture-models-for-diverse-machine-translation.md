---
layout: post
title: paper translation 
date: 2019-03-01 22:25:24.000000000 +09:00
---

> Mixture Models for Diverse Machine Translation: Tricks of the Trade

摘要

通过EM训练的混合模型是机器学习文献中最简单，使用最广泛且易于理解的潜变量模型。令人惊讶的是，这些模型在诸如机器翻译之类的文本生成应用中几乎没有被探索过。原则上，它们提供了一个潜在的变量来控制生成并产生一系列不同的假设。然而，在实践中，混合模型易于退化 - 通常只有一个组件被训练或潜在变量被简单地忽略。我们发现，在责任计算中禁用辍学噪声对于成功培训至关重要。此外，参数化，先验分布，硬与软EM和在线与离线分配的设计选择可以显着影响模型性能。我们开发了一个评估协议，以评估多个参考的质量和多样性，并提供了几个混合模型变体的广泛实证研究。我们的分析表明，与变分模型和不同的解码方法相比，某些类型的混合模型更加稳健，并且在翻译质量和多样性之间提供了最佳平衡.

1.导言

机器翻译（MT）是一项具有挑战性的任务，不仅因为大而结构化的输出空间，而且因为它本质上是一对多的映射。 由于不同语言之间的信息不对称，通常存在许多合理和语义上等同的翻译，例如，从没有语法性别的语言翻译成具有语法性别的语言导致两种有效的翻译选项，以及不同的翻译风格，例如形式/ 非正式的，文字的/非文字的等
这提出了如何建模这种多模态输出分布以及如何评估这些模型的问题。

我们的第一个贡献是一个更好的评估协议，在评估过程中使用多个参考来衡量翻译的质量和生成的假设集的多样性。 本文的第二个贡献是对机器翻译混合模型的深入实证分析，尽管我们推测这些研究结果是一般的，可能适用于其他文本生成任务，如对话，摘要，图像标题等。

条件混合模型，也称为专家混合物（MoE）（Jacobs等，1991），原则上非常适合产生可通过不同混合物组分实现的各种假设。 然而，它们在很大程度上被忽视，有利于具有更丰富潜在结构的模型（Zhang et al。，2016; Kaiser et al。，2018）。 以前有一些关于序列到序列学习的混合模型的研究（Shazeer等，2017; He等，2018），但这些并没有在质量和多样性方面对生成进行评估，或者它们关注于特定的模型变体。 关于混合模型还有一些尚待商榷的问题，是否可以与依赖于近似贝叶斯推断的更复杂模型竞争，是否它们受到与变分模型相同的“后塌陷”简并性的困扰（Bowman等，2016），模型配置如何影响模型表现以及哪一个配置在实践中效果最佳。

这项工作考虑了混合模型构建中涉及的所有主要设计选择，包括硬与软EM训练，混合组件的不同参数化，条件先验的选择，责任的更新频率（也称为成员权重），以及正则化噪声的方式 注入。 我们使用最先进的模型架构在大规模WMT英语到德语基准测试中进行实验，结果表明这些设计选择之间存在复杂的依赖关系。
他们还揭示了一些成分是成功训练混合模型的关键。

首先，我们证明混合模型在受到dropout噪声训练时容易出现退化现象，但这可以通过关闭责任计算中的dropout来减轻。 专家专业化的关键是要始终如一地使用它们，即使少量的正则化噪声也会妨碍它。
第二，硬混合产生比软质混合物更多样化的生成，类似于K-Means倾向于发现与高斯混合物发现的平均值相比彼此相距更远的质心（Kearns等，1998）。 第三，采用统一的先验鼓励所有混合成分为任何输入源句产生良好的翻译，这是非常需要的。 最后，比起共享参数使用独立参数化的混合物组分提供更大的多样化
容量; 但是如果责任在线刷新，那么独立参数化很容易出现只有一个组件被训练的“退化”，因为“富有者更丰富”的效应。 相反，共享参数和离线责任分配的组合可能导致另一种退化————混合物组件不能专门化并且表现相同。

我们将评估扩展到三个WMT基准数据集，其中测试集有多个人的参考。 我们证明混合模型在成功训练后，始终优于变分NMT（Zhang et al。，2016）、多样化解码算法————多样化beam search（Vijayakumar等，2016; Li等，2017）、以及偏差采样（ Graves，2013; Fan等，2018）。 我们的定性分析表明，不同的混合组件可以在不同样本上捕获一致的翻译样式，使用户能够以可解释和语义上有意义的方式控制生成。

2.相关工作

之前的研究调查了机器翻译中的预测不确定性。 Dreyer＆Marcu（2012）和Galley等人（2015）引入了新的指标来解决评估时的不确定性。奥特等人（2018a）检查了不确定性的来源，并提出了检查模型和数据分布之间拟合的工具。他们还观察到现代的条件自回归NMT模型只能在有限的范围内捕获不确定性，并且它们倾向于在假设空间上过度平滑的概率质量。

最近的工作探索了机器翻译的潜变量建模。张等人（2016）利用变分推理（Kingma＆Welling，2013; Bowman等，2016）来增强具有单个高斯潜变量的NMT系统。 Schulz等人扩展了这项工作（2018），他们考虑了一系列潜在的高斯变量来表示每个目标词。凯撒等人（2018）提出了一个类似的模型，但具有一组离散的多项式潜变量。在他们的定性分析中，凯撒等人
（2018）表明潜在码确实以有趣的方式影响输出预测，但他们的重点是加速常规解码而不是产生一组不同的假设。至今还没有对潜在变量导致的多样性的分析与量化工作。

最相关的工作是由He等人完成的（2018），他建议使用具有统一先验的软混合模型进行多样化的机器翻译。 但是，他们没有在具有多个参考的数据集上进行评估，也没有分析建立混合模型的全部设计选择。 此外，他们使用较弱的基础模型，并没有与变分NMT或不同的解码基线进行比较，这使得他们的实证分析不那么确凿。 我们
提供全面的研究，并阐明混合模型在各种环境中的不同行为。

除了机器翻译之外，还有关于对话生成的潜在变量（Serban et al。，2017; Cao＆Clark，2017; Wen et al。，2017）和图像标题（Wang et al。，2017; Dai et al。，2017年）。 本文提出的混合模型偏离了这些基于VAE或GAN的方法，重要的是，它更简单。 它也可以应用于其他文本生成任务。


补充资料： 

1.GAN：对抗生成网络   

> https://www.leiphone.com/news/201706/ty7H504cn7l6EVLd.html

摘抄一段比较有内涵的：

“有人说GAN强大之处在于可以自动的学习原始真实样本集的数据分布，不管这个分布多么的复杂，只要训练的足够好就可以学出来。针对这一点，感觉有必要好好理解一下为什么别人会这么说。

我们知道，传统的机器学习方法，我们一般都会定义一个什么模型让数据去学习。比如说假设我们知道原始数据属于高斯分布呀，只是不知道高斯分布的参数，这个时候我们定义高斯分布，然后利用数据去学习高斯分布的参数得到我们最终的模型。再比如说我们定义一个分类器，比如SVM，然后强行让数据进行东变西变，进行各种高维映射，最后可以变成一个简单的分布，SVM可以很轻易的进行二分类分开，其实SVM已经放松了这种映射关系了，但是也是给了一个模型，这个模型就是核映射（什么径向基函数等等），说白了其实也好像是你事先知道让数据该怎么映射一样，只是核映射的参数可以学习罢了。所有的这些方法都在直接或者间接的告诉数据你该怎么映射一样，只是不同的映射方法能力不一样。那么我们再来看看GAN，生成模型最后可以通过噪声生成一个完整的真实数据（比如人脸），说明生成模型已经掌握了从随机噪声到人脸数据的分布规律了，有了这个规律，想生成人脸还不容易。然而这个规律我们开始知道吗？显然不知道，如果让你说从随机噪声到人脸应该服从什么分布，你不可能知道。这是一层层映射之后组合起来的非常复杂的分布映射规律。然而GAN的机制可以学习到，也就是说GAN学习到了真实样本集的数据分布。”

2.VAE：变分自动编码器

> http://kvfrans.com/variational-autoencoders-explained/


