---
layout: post
title: paper translation 
date: 2019-03-01 22:25:24.000000000 +09:00
---

> Mixture Models for Diverse Machine Translation: Tricks of the Trade

摘要

通过EM训练的混合模型是机器学习文献中最简单，使用最广泛且易于理解的潜变量模型。令人惊讶的是，这些模型在诸如机器翻译之类的文本生成应用中几乎没有被探索过。原则上，它们提供了一个潜在的变量来控制生成并产生一系列不同的假设。然而，在实践中，混合模型易于退化 - 通常只有一个组件被训练或潜在变量被简单地忽略。我们发现，在责任计算中禁用辍学噪声对于成功培训至关重要。此外，参数化，先验分布，硬与软EM和在线与离线分配的设计选择可以显着影响模型性能。我们开发了一个评估协议，以评估多个参考的质量和多样性，并提供了几个混合模型变体的广泛实证研究。我们的分析表明，与变分模型和不同的解码方法相比，某些类型的混合模型更加稳健，并且在翻译质量和多样性之间提供了最佳平衡.

1.导言

机器翻译（MT）是一项具有挑战性的任务，不仅因为大而结构化的输出空间，而且因为它本质上是一对多的映射。 由于不同语言之间的信息不对称，通常存在许多合理和语义上等同的翻译，例如，从没有语法性别的语言翻译成具有语法性别的语言导致两种有效的翻译选项，以及不同的翻译风格，例如形式/ 非正式的，文字的/非文字的等
这提出了如何建模这种多模态输出分布以及如何评估这些模型的问题。

我们的第一个贡献是一个更好的评估协议，在评估过程中使用多个参考来衡量翻译的质量和生成的假设集的多样性。 本文的第二个贡献是对机器翻译混合模型的深入实证分析，尽管我们推测这些研究结果是一般的，可能适用于其他文本生成任务，如对话，摘要，图像标题等。

条件混合模型，也称为专家混合物（MoE）（Jacobs等，1991），原则上非常适合产生可通过不同混合物组分实现的各种假设。 然而，它们在很大程度上被忽视，有利于具有更丰富潜在结构的模型（Zhang et al。，2016; Kaiser et al。，2018）。 以前有一些关于序列到序列学习的混合模型的研究（Shazeer等，2017; He等，2018），但这些并没有在质量和多样性方面对生成进行评估，或者它们关注于特定的模型变体。 关于混合模型还有一些尚待商榷的问题，是否可以与依赖于近似贝叶斯推断的更复杂模型竞争，是否它们受到与变分模型相同的“后塌陷”简并性的困扰（Bowman等，2016），模型配置如何影响模型表现以及哪一个配置在实践中效果最佳。

这项工作考虑了混合模型构建中涉及的所有主要设计选择，包括硬与软EM训练，混合组件的不同参数化，条件先验的选择，责任的更新频率（也称为成员权重），以及正则化噪声的方式 注入。 我们使用最先进的模型架构在大规模WMT英语到德语基准测试中进行实验，结果表明这些设计选择之间存在复杂的依赖关系。
他们还揭示了一些成分是成功训练混合模型的关键。

首先，我们证明混合模型在受到dropout噪声训练时容易出现退化现象，但这可以通过关闭责任计算中的dropout来减轻。 专家专业化的关键是要始终如一地使用它们，即使少量的正则化噪声也会妨碍它。
第二，硬混合产生比软质混合物更多样化的生成，类似于K-Means倾向于发现与高斯混合物发现的平均值相比彼此相距更远的质心（Kearns等，1998）。 第三，采用统一的先验鼓励所有混合成分为任何输入源句产生良好的翻译，这是非常需要的。 最后，比起共享参数使用独立参数化的混合物组分提供更大的多样化
容量; 但是如果责任在线刷新，那么独立参数化很容易出现只有一个组件被训练的“退化”，因为“富有者更丰富”的效应。 相反，共享参数和离线责任分配的组合可能导致另一种退化————混合物组件不能专门化并且表现相同。

我们将评估扩展到三个WMT基准数据集，其中测试集有多个人的参考。 我们证明混合模型在成功训练后，始终优于变分NMT（Zhang et al。，2016）、多样化解码算法————多样化beam search（Vijayakumar等，2016; Li等，2017）、以及偏差采样（ Graves，2013; Fan等，2018）。 我们的定性分析表明，不同的混合组件可以在不同样本上捕获一致的翻译样式，使用户能够以可解释和语义上有意义的方式控制生成。

2.相关工作

之前的研究调查了机器翻译中的预测不确定性。 Dreyer＆Marcu（2012）和Galley等人（2015）引入了新的指标来解决评估时的不确定性。奥特等人（2018a）检查了不确定性的来源，并提出了检查模型和数据分布之间拟合的工具。他们还观察到现代的条件自回归NMT模型只能在有限的范围内捕获不确定性，并且它们倾向于在假设空间上过度平滑的概率质量。

最近的工作探索了机器翻译的潜变量建模。张等人（2016）利用变分推理（Kingma＆Welling，2013; Bowman等，2016）来增强具有单个高斯潜变量的NMT系统。 Schulz等人扩展了这项工作（2018），他们考虑了一系列潜在的高斯变量来表示每个目标词。凯撒等人（2018）提出了一个类似的模型，但具有一组离散的多项式潜变量。在他们的定性分析中，凯撒等人
（2018）表明潜在码确实以有趣的方式影响输出预测，但他们的重点是加速常规解码而不是产生一组不同的假设。至今还没有对潜在变量导致的多样性的分析与量化工作。

最相关的工作是由He等人完成的（2018），他建议使用具有统一先验的软混合模型进行多样化的机器翻译。 但是，他们没有在具有多个参考的数据集上进行评估，也没有分析建立混合模型的全部设计选择。 此外，他们使用较弱的基础模型，并没有与变分NMT或不同的解码基线进行比较，这使得他们的实证分析不那么确凿。 我们
提供全面的研究，并阐明混合模型在各种环境中的不同行为。

除了机器翻译之外，还有关于对话生成的潜在变量（Serban et al。，2017; Cao＆Clark，2017; Wen et al。，2017）和图像标题（Wang et al。，2017; Dai et al。，2017年）。 本文提出的混合模型偏离了这些基于VAE或GAN的方法，重要的是，它更简单。 它也可以应用于其他文本生成任务。

3. 用于多样化机器翻译的混合模型

含有公式的段落不方便写，大致写一下思路

训练： 采用EM算法  有多种方法可以跨样本使用E-M算法(Neal & Hinton, 1998);

解码：  取K个分量中，概率最大的一个。此法方便并行。

退化：

  不幸的是，用于文本生成的混合模型的天真实现容易出现两种主要类型的退化：
  
D1：只有一个组件得到训练（Eigen et al。，2014; Shazeer et al。，2017），因为“丰富者更丰富”的效果，一旦一个组件比其他组件略好，它总是被挑选而其他组件饿死，最终从未使用过。

D2：潜在变量被忽略，类似于变分自动编码器的崩溃，其中后验总是等于先验（Bowman等，2016）。

在这两种情况下，模型都像基线模型一样运行，没有任何潜在变量的好处。 然而，在实践中，这些退化的可能性受到许多设计决策的严重影响，我们将在以下小节中对其进行描述。

3.1 模型变体

理想情况下，我们希望不同的专家专注于不同的翻译风格，因此他们可以产生不同的假设。 此外，我们希望所有这些都适用于任何源句，因此它们将产生高质量的翻译。 为此，我们探索了规范混合模型的几种变体，这些变体取决于它们是使用硬（h）还是软（s）赋值，以及它们是使用学习先验（lp）还是统一先验（up）。

硬E—step:每次优化只优化对应概率最大的组件

于是，我们一共有4种变体。在这些变体中，hMup目标也被称为多选择学习（MCL），用于最小化oracle损失的学习者集合（Guzman-Rivera等，2012）和He等。 （2018）已经考虑了sMup目标来训练序列到序列的混合模型。

3.2 参数化

混合模型的另一个重要设计决策是专家之间的参数共享程度。使用独立参数化的专家为他们提供额外的能力，使其彼此区分，但可能会加剧过度拟合，因为参数的数量随着专家的数量线性增加。另一方面，在专家之间共享参数可以帮助减轻退化D1————忽略低质量专家并且最终在训练期间“死亡”，因为通过共享参数，甚至不受欢迎的专家也会获得一些梯度。

我们使用独立和共享参数测试不同的模型变体。通过独立参数化，每个专家都有不同的解码器网络。通过共享参数化，专家使用相同的解码器网络，但是在目标序列<bos>开始处的句子开头标记被替换为潜在变量的嵌入表示。这在基线模型上的参数增加可忽略不计。

3.3 训练模式

我们考虑在训练期间在E-step和M-step之间交替时采用两个schedule：在线和离线。 在在线EM算法中，我们通过随机梯度下降最小化损失，有效地交错每个小批量的Estep和Mstep（Lee等人，2016）。 相比之下，离线EM算法对所有训练样例执行E步骤，然后用Estep所产生的责任训练每个专家到收敛，并重复。 在实践中，对于离线训练，我们在重新估计职责之前仅执行单个时期的M步骤而不是训练其到收敛。

3.4 正则

具有大量参数的深度神经网络易于过度拟合，并且通常采用通过dropout的正则化来实现良好的泛化性能。 然而，随着训练的进行，让专家多样化的关键是要始终如一地使用它们，我们发现即使在责任计算中存在少量的正规化噪声（E步骤）也会妨碍这一点。 实际上，我们在5.1中表明，使用dropout导致混合模型忽略潜在变量，但这种退化是通过禁用E步骤中的dropout来缓解。 我们在附录A中更详细地探讨了这一现象。

4. 指标

在本节中，我们将描述用于定量评估一组翻译假设(hypothesis)的质量和多样性的指标。 我们使用BLEU（Papineni等，2002）作为测量有序句对（u，v）的相似性的基础，其中u是假设，v是参考。 references: {y^1, y^2, .... , y^M}   source： x   hypothesis: {y_hat^1,.....,y_hat^K}

有两个指标：一个是平均oracle BLEU，这衡量了假设集的整体质量。 如果该指标得分较低，则意味着某些生成的假设与任何参考都不匹配，假设生成质量较差；一个是成对BLEU，该度量标准衡量假设之间的相似性。 假设集越多样化，成对BLEU越低。 理想情况下，我们希望一个模型的成对BLEU可以匹敌人类的成对BLEU。

同样计算了人类翻译的两个指标，不同的是，人类的评价指标是leave-one-out方式，即拿一个reference去跟其他的N-1reference对比。

§3中概述的简并可以通过这些指标轻松识别：第一个退化是指单个专家负责所有输入的情况（D1）。 当我们测量非常低的成对BLEU以及非常低的平均oracle BLEU时，可以识别这种情况，即除了一个之外的所有潜在变量都产生非常差的生成。 第二次退化指忽略潜在变量，因此所有专家的行为几乎完全相同时（D2）。 当我们观察到良好的平均oracle BLEU但非常高的成对BLEU（接近100）时，即当所有潜在值给出良好但非常相似的输出时，可以认为是D2。





补充资料： 

1.GAN：对抗生成网络   

> https://www.leiphone.com/news/201706/ty7H504cn7l6EVLd.html

摘抄一段比较有内涵的：

“有人说GAN强大之处在于可以自动的学习原始真实样本集的数据分布，不管这个分布多么的复杂，只要训练的足够好就可以学出来。针对这一点，感觉有必要好好理解一下为什么别人会这么说。

我们知道，传统的机器学习方法，我们一般都会定义一个什么模型让数据去学习。比如说假设我们知道原始数据属于高斯分布呀，只是不知道高斯分布的参数，这个时候我们定义高斯分布，然后利用数据去学习高斯分布的参数得到我们最终的模型。再比如说我们定义一个分类器，比如SVM，然后强行让数据进行东变西变，进行各种高维映射，最后可以变成一个简单的分布，SVM可以很轻易的进行二分类分开，其实SVM已经放松了这种映射关系了，但是也是给了一个模型，这个模型就是核映射（什么径向基函数等等），说白了其实也好像是你事先知道让数据该怎么映射一样，只是核映射的参数可以学习罢了。所有的这些方法都在直接或者间接的告诉数据你该怎么映射一样，只是不同的映射方法能力不一样。那么我们再来看看GAN，生成模型最后可以通过噪声生成一个完整的真实数据（比如人脸），说明生成模型已经掌握了从随机噪声到人脸数据的分布规律了，有了这个规律，想生成人脸还不容易。然而这个规律我们开始知道吗？显然不知道，如果让你说从随机噪声到人脸应该服从什么分布，你不可能知道。这是一层层映射之后组合起来的非常复杂的分布映射规律。然而GAN的机制可以学习到，也就是说GAN学习到了真实样本集的数据分布。”

2.VAE：变分自动编码器

> http://kvfrans.com/variational-autoencoders-explained/



