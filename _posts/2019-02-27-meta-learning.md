---
layout: post
title: paper translation 之 abstract introduction
date: 2019-02-27 21:25:24.000000000 +09:00
---

https://zhuanlan.zhihu.com/p/35379027

"而因为任意的知识都可以通过神经网络来表示，因此呢，我们就想：为什么不用一个神经网络来表示这个视觉比较能力呢？然后利用这个网络去做少样本学习？"

"因此，我们这篇paper也是想给大家一个启示，用神经网络进一步的去替代一些之前还是人为设计的东西，有希望取得更好的效果！像目前元学习（Meta Learning）在研究的一个方向就是用神经网络学习来生成网络结构，也是一个意思。"

“其他领域有多少问题其实也是依靠元知识Meta Knowledge来驱动的？”如果我们发现了这样元知识的需求，我们就可以考虑使用类似的方法，元学习（Meta Learning）的方法来实现。

> AUDIO-LINGUISTIC EMBEDDINGS FOR SPOKEN SENTENCES

abstract

我们提出了能够捕获两者的口语句子嵌入声学和语言内容。 虽然现有作品在字符，音素或单词级别上运行，但我们的方法通过在句子级别建模语音来学习长期依赖性。 作为音频语言多任务学习问题，我们的编码器 - 解码器模型同时从音频重建声学和自然语言特征。我们的结果表明，口语句子嵌入在语音识别和情感识别任务上优于音素和词级基线。 消融研究表明我们的嵌入可以更好地模拟高级声学概念，同时保留语言内容。 总的来说，我们的工作说明了通用，多模态句子嵌入对口语理解的可行性。

introduction

在口头交流中，人类处理多个顺序的话，往往等待一个完整的句子
完成。然而，许多书面和口头语言系统隐式或明确地依赖于个别角色和词级表示。缺乏句子级别的上下文会使句子难以理解包含连词[1]，否定[2]和声调变种[3]。在这项工作中，我们调查了嵌入口语处理领域并提出口语句子嵌入，能够对声学和声学进行建模单个潜在代码中的语言内容。

单词的机器表示可以追溯到ASCII。这个单热表示使用a编码每个字符虚拟或指示变量的混合。虽然这是慢慢扩展到单词，语言的大量词汇量使其变得困难。学习或分布，单词矢量陈述[4]取代了单热编码。这句话矢量能够捕获语义信息，包括相邻词语的上下文。即便在今天，社区继续构建更好的上下文单词嵌入，例如ELMo [5]，ULMFit [6]和BERT [7]。单词，音素和像Speech2Vec [8]和Char2Wav这样的字形嵌入[9]也被提出用于speceh，遵循技术从自然语言的理解。

虽然词级嵌入是有前途的，但由于几个原因，它们通常不足以用于与语音相关的任务。首先，单词和音素嵌入捕获一个狭窄的时间上下文，通常最多几百毫秒。如结果，这些嵌入不能捕获更高级别推理所需的长期依赖性（例如段落或歌曲级别的理解）。几乎所有的系统
语音识别注重地方语境的正确性（例如，字母，单词和音素）而不是整体语义。第二，语音识别，外部语言模型通常用于纠正字符和单词级别的预测。这需要添加复杂的多假设生成方法[10]。句子级嵌入提供了超越单词的优点和字符嵌入。句子级嵌入可以捕捉不同单词的潜在因素。这对于直接有用更高级别的音频任务，如情感识别，韵律
建模和音乐风格分析。此外，大多数外部语言模型在句子级别运作。通过单个句子级嵌入，嵌入可以在较长的上下文窗口大小捕获声学和语言内容 - 从而减少对外部的需求，通过语言模型完全通过学习时间结构。

贡献。 

在这项工作中，我们的贡献是双重的。 首先，我们建议从音素，角色和词级表示对句子层次的理解学习口语句子嵌入。 其次，我们设计这种嵌入捕获语言和声学内容，以学习可适用的潜在代码各种语言和语言任务。 我们验证质量嵌入我们的消融研究，我们评估句子级嵌入在用于自动语音识别和情感分类时的一般性。 我们相信这项工作将激发未来的语音处理工作，语义理解和多模态转移学习。

