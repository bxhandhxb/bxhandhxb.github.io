---
layout: post
title: Text2image
date: 2019-03-08 19:32:24.000000000 +09:00
---

今天翻译两篇text2image的论文。

> Text-to-image Synthesis via Symmetrical Distillation Networks

摘要

文本到图像合成旨在根据用户给出的文本描述自动生成图像，这是一项极具挑战性的任务。文本到图像合成的主要问题在于两个空白：异质和同质的差距。异构差距介于文本描述的高级概念和图像的像素级内容之间，而合成图像分布与实际图像分布之间存在同质差距。为了解决这些问题，我们利用通用判别模型（例如VGG19）的出色能力，可以在多个层面上指导新生成模型的训练过程，以弥合这两个空白。高级表示可以教导生成模型从文本描述中提取必要的视觉信息，这可以弥合异质性差距。中级和低级表示可以使其分别学习图像的结构和细节，从而减轻了同质性差距。因此，我们提出了对称蒸馏网络（SDN），其由作为“教师”的源判别模型和作为“学生”的目标生成模型组成。目标生成模型具有源对称模型的对称结构，以便可访问地传递分层知识。此外，我们将训练过程分解为两个阶段，使用不同的蒸馏范例来提升目标生成模型的性能。对两个广泛使用的数据集进行了实验，以验证我们提出的SDN的有效性。

1.导言

作为一种多媒体技术，跨模态检索[6,20,29,38,43]已成为大数据时代研究的一个突出主题。但是，跨模式检索有时无法满足用户的需求，因为它只能为用户提供现有数据。因此，跨模态合成的研究越来越受到社会的关注，如文本到图像的合成。文本到图像合成可以自动从文本描述生成图像。这是一项充满希望但具有挑战性的任务，它有两个主要问题。一方面，文本描述中的高级概念与合成图像的像素级内容之间存在异质差距。异质gap对应于输入文本描述和生成的图像之间的语义相关性。另一方面，由于巨大的图像像素空间，在合成和实际图像分布之间存在同质的gap。同质的gap反映在合成图像的真实性和质量上，包括全局结构和局部细节。因此，文本到图像合成的目标是弥合这些差距并生成具有高真实性，质量和语义相关性的图像，这些图像以文本描述为条件。

为了解决上述问题，我们考虑了判别任务的一般范式。 存在一种判别任务的一般范例，即首先通过标记图像的大规模数据集训练通用特征表示模型，然后针对特定任务微调模型[41]。 我们可以在各种最先进的方法中找到这种范例的许多成功应用，例如对象检测[7]，语义分割[21]和细粒度图像分类

相比之下，生成任务没有通用模型，大多数基于深度神经网络的现有生成方法都是从头开始训练他们的模型。然而，通用判别模型具有很强的产生多层次表示的能力，这可以通过反转和理解它的研究来验证[5,23,45]。通过反转和理解，可以注意到这些多级表示包含从像素内容到语义概念的分层信息。因此，利用通用判别模型的能力，有助于弥合文本到图像合成的异构和同质间隙。通用判别模型通常基于图像分类任务，并且可以预测输入图像的语义标签。它可以将图像的像素级内容映射到高级概念，这是针对文本到图像合成的逆过程。因此，通用判别模型产生的高级表示可以作为生成模型的指导，教导它们从文本描述中提取必要的视觉信息并弥合异质性差距。此外，中层和低层表示可以引导生成模型分别学习图像的结构和细节，从而减轻均匀间隙问题。与高维图像像素空间相比，更容易在这些低维特征空间中找到合成图像的最佳表示。因此，通过通用判别模型训练文本到图像合成的生成模型具有显着的优点。

在本文中，我们提出了对称蒸馏网络（SDN），以充分利用通用判别模型的强大功能，用于文本到图像合成的生成模型。 “蒸馏”范式受到[14]的启发。 Hinton等人。 [14]从Bucilua等人的模型压缩思想提出了“蒸馏”概念。 [3]，它可以将在大型数据集上训练的大型模型压缩到更小的模型。 我们的工作进一步将这一理念扩展到通用判别模型和新的生成模型之间。

> 补充材料  知识蒸馏  https://www.leiphone.com/news/201804/upBV7Zpd1jnsB9lf.html

我们设计了SDN的对称结构，包括源判别模型和目标生成模型（以下分别称为“源模型”和“目标模型”）。 源模型是通用判别模型（例如VGG19 [34]），并且目标生成模型具有相同的层但是与源模型的数据流方向相反。 对称结构使得可以在多个相应级别上从源模型向目标模型提取知识。

此外，我们设计了两个不同阶段的蒸馏方式：Stage-I和Stage-II蒸馏。 通过Stage-I蒸馏，目标模型从源模型粗略地给出的表示中学习，其以文本描述为条件绘制几乎包含所有视觉信息的模糊图像。 通过Stage-II蒸馏，目标模型更多地了解合成图像和真实图像之间在多个层次上的微小差异，最终合成具有关于对象的更多细节的图像。

我们在两个广泛使用的数据集上使用最先进的方法进行比较实验，以验证我们提出的SDN的有效性。 此外，进行了几个基线实验来分析不同组分的重要性。

2.相关工作

由于深度网络[19]，近年来图像生成取得了巨大进步。尽管像[25]这样的早期工作只能产生易于与实际样本区分的合成图像，但最近的工作[4,26,42]可以合成照片般逼真的图像。有一些典型的深度图像生成方法促进了这一进步。金马等人。通过使用概率图形模型并最大化数据可能性的下限来提出变分自动编码器（VAE）[17]以制定生成问题。 Goodfellow等人。提出生成性对抗网络（GAN）[8]在对抗范式中训练具有判别模型的生成模型。 Deep Recurrent Attention Writer（DRAW）方法[9]可以使用循环变分自动编码器和注意机制生成逼真的图像。作为一种自回归方法，PixelRNN [28]通过对像素空间中的条件分布建模来实现图像合成。此外，已经证明可以实现基于这些生成方法的条件图像生成，其具有更灵活的应用[36,40]。

在过去几年中，越来越多的研究人员关注文本到图像合成问题，这是一个以文本描述为条件的图像生成任务。由于文本图像合成的主要问题在于同质和异质gap，现有方法已经考虑了这些问题并试图对其进行处理。早期的工作更侧重于异质性gap。 Mansimov等[24]引入了AlignDRAW模型，通过软注意机制估计生成的图像和文本描述之间的对齐。但是，注意机制忽略了文本描述的一些视觉详细信息。里德等人[31]结合深对称结构化关节嵌入[30]和GAN [8]。嵌入方法可以挖掘生成图像的更详细的视觉信息，但由于基本的异构相关约束而不能充分利用这些信息。为了弥合均质的差距，Reed等人[32]建议GAWWN同时按对象和部分关键点位置约束控制全局结构。该方法可以成功生成具有正确对象形状和颜色的图像，但仍然缺乏细节的真实性。为了减轻均质gap问题，StackGAN [42]将文本到图像合成任务分为两个阶段。 StackGAN通过第一阶段的粗糙结构生成图像，并使用这些图像在第二阶段进一步生成具有更多局部细节的图像。受第一阶段的限制，最终生成的图像的结构具有一些不切实际的特征，并且仍存在均质的差距。

我们提出的SDN的生成模型不是在以前的方法中广泛使用的对抗性训练，而是具有前馈结构，并在通用判别模型的指导下学习。 有了这个范例，SDN不需要极小极大优化和两个对抗模型的仔细参数调整，这比当前基于GAN的方法更稳定[1]。

3.对称蒸馏网络

如图2所示，我们的SDN由源判别模型和目标生成模型组成，具有对称结构。 在训练阶段，有两个蒸馏阶段，通过多层次表示将知识从源模型转移到目标模型。 在测试阶段，SDN最终可以合成具有对象多级特征的图像。 此外，由于给定的文本描述可以对应于许多图像，因此我们将SDN扩展到不同的范例。

3.1 初步

