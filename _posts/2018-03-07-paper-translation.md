---
layout: post
title: Graph-to-Sequence Learning using Gated Graph Neural Networks
date: 2019-03-07 21:05:24.000000000 +09:00
---

摘要

许多NLP应用程序可以构建为图形到序列的学习问题。 与基于语法的方法相比，先前提出的关于此设置的神经架构的工作获得了有希望的结果，但仍依赖于线性化启发式和/或标准循环网络以实现最佳性能。 在这项工作中，我们提出了一个新模型，它对图中包含的完整结构信息进行编码。 我们的架构将最近提出的门控图形神经网络与输入转换相结合，允许节点和边缘具有自己的隐藏表示，同时解决以前工作中出现的参数爆炸问题。 实验结果表明，我们的模型在AMR图和基于语法的神经机器翻译中优于生成强基线。

前言

图形结构在自然语言的表示中无处不在。 特别是，许多全句语义框架使用有向无环图作为基础形式，而大多数基于树的句法表示也可以看作图。 可以将一系列NLP应用框架化为将图结构转换为序列的过程。 例如，语言生成可以涉及将语义图实现为表面形式，并且句法机器翻译涉及将树注释的源句子转换为其翻译。

此设置中的先前工作依赖于基于语法的方法，例如树传感器（Flanigan等人，2016）和hyperedge替换语法（Jones等人，2012）。 这些方法的关键限制是需要图节点和表面标记之间的对齐。 这些对齐通常是自动生成的，因此在构建语法时它们可以传播错误。 最近的方法将图形转换为线性化形式，并使用现成的方法，如基于短语的机器翻译（Pourdamghani等，2016）或神经序列到序列（以下称为s2s）模型（Konstas等，2017年）。 这些方法忽略了完整的图形结构，丢弃了关键信息。

在这项工作中，我们提出了一个图形序列（以下称为g2s）学习模型，该模型利用了神经编码器 - 解码器架构的最新进展。 具体而言，我们采用基于门控图神经网络（Li et al。，2016，GGNNs）的编码器，该编码器可以包含完整的图形结构而不会丢失信息。 这种网络将边缘信息表示为标签方式参数，即使对于小尺寸标签词汇表（大约数百个）也可能存在问题。 为了解决这个限制，我们还引入了一个图形转换，它将边缘更改为其他节点，解决了参数爆炸问题。 这也确保了边缘具有图形特定的隐藏向量，这为网络中的关注和解码模块提供了更多信息。

我们在两个图形序列问题中对我们的模型进行基准测试，从抽象意义表示（AMR）生成和使用源依赖信息的神经机器翻译（NMT）。 与以前的工作相比，我们的方法在不依赖标准RNN编码器的情况下优于两个任务中强大的s2s基线。 特别是，对于NMT，我们通过在依赖关系树中的连续单词之间添加连续边来表明我们避免了对RNN的需要。 这说明了我们方法的一般性：语言偏差可以通过简单的图形转换添加到输入中，而无需更改模型体系结构。

